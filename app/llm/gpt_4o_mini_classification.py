from together import Together
import json
import os
from openai import AzureOpenAI
from dotenv import load_dotenv
import asyncio
from contextlib import asynccontextmanager
from openai import AsyncAzureOpenAI
from app.modals.newsEntity import NewsEntity

load_dotenv()

# ---------------- Azure OpenAI Config ----------------
TOGETHER_AI_API_KEY = os.getenv("TOGETHER_AI_API_KEY")

if not TOGETHER_AI_API_KEY:
    raise ValueError("Please set TOGETHER_AI_API_KEY in your environment.")

# One-time client
client = Together(api_key=TOGETHER_AI_API_KEY)

# Concurrency limiter (tune this for your quota)
LLM_CONCURRENCY = int(os.getenv("LLM_CONCURRENCY", "8"))
_llm_semaphore = asyncio.Semaphore(LLM_CONCURRENCY)

# Optional: strict JSON response (supported on 2024-06-01+ and newer models)
RESPONSE_FORMAT = {"type": "json_object"}


# LLAMA:meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
# Alibaba: Qwen/Qwen2.5-7B-Instruct-Turbo

def _normalize_key(k: str) -> str:
    # Map fancy tags like "**decontextualisation**Ôºà...Ôºâ" to simple slug keys
    k = k.strip().lower()
    # strip markdown asterisks and Chinese annotations
    k = k.replace("**", "")
    k = k.split("Ôºà")[0].strip()
    k = k.replace(" ", "_").replace("-", "_")
    return k

def _empty_analysis():
    return {
    "refined_title": None,
    "journalistic_demerits": {},
    "journalistic_merits": {},
    "reporting_style": [],
    "reporting_intention": [],
    "error": "Failed to parse model output"
    }

ALLOWED_TAGS = {
    "journalistic_merits": [
        "**multiple_perspectives**ÔºàÂ§öÂÖÉËßÄÈªûÔºâ",
        "**logical_flow**ÔºàÈÇèËºØÊ∏ÖÊô∞Ôºâ",
        "**use_of_real_world_examples**ÔºàÂØ¶‰æãÂÖ∑È´îÔºâ",
        "**constructive_criticism**ÔºàÂÖ∑Âª∫Ë®≠ÊÄßÊâπË©ïÔºâ",
        "**avoidance_of_nationalism_or_populism**ÔºàÈÅøÂÖçÊ∞ëÊóè‰∏ªÁæ©ÊàñÊ∞ëÁ≤π‰∏ªÁæ©Ôºâ",
        "**source_transparency**ÔºàÊ∂àÊÅØ‰æÜÊ∫êÈÄèÊòéÔºâ",
        "**clarification_of_uncertainty**ÔºàÊæÑÊ∏Ö‰∏çÁ¢∫ÂÆöÊÄßÔºâ",
        "**background_context**ÔºàËÉåÊôØËÑàÁµ°ÂÖÖÂàÜÔºâ",
        "**transparency_of_process(Â†±Â∞éÈÅéÁ®ãÈÄèÊòé)",
        "**depth_of_analysis** (ÂàÜÊûêÊ∑±ÂÖ•)",
        "**engagement_with_complexity** (ÊúâËôïÁêÜË≠∞È°åÁöÑË§áÈõúÊÄß)",
        "**local_relevance_and_contextualization** (Âú®Âú∞ËÑàÁµ°ÂåñËàáÈóúËÅØÊÄß)",
        "**independence_from_power** (Â†±Â∞éÁç®Á´ãÊÄßÂº∑)",
        "**clarity_of_purpose** (Â†±Â∞éÁõÆÁöÑÊòéÁ¢∫)",
        "**accountability_framing**ÔºàÊåÅ‰ªΩËÄÖË≤¨‰ªªÊ≠∏Â±¨ÊòéÁ¢∫Ôºâ",
        "**ethical_reporting**ÔºàÂÖ∑ÂÄ´ÁêÜÊÑèË≠òÁöÑÂ†±Â∞éÔºâ",
        "**use_of_data**ÔºàÂñÑÁî®Êï∏ÊìöÔºâ",
        "**cultural_humility**ÔºàÂ±ïÁèæÊñáÂåñË¨ôÈÅúÔºâ",
        "**centering_affected_voices**ÔºàÂá∏È°ØÁï∂‰∫ãËÄÖËßÄÈªûÔºâ",
        "**readability**ÔºàË°®ÈÅîÊòìÊáÇÔºâ",
        "**headline_reflects_content**ÔºàÊ®ôÈ°åËàáÂÖßÊñá‰∏ÄËá¥Ôºâ",
        "**public_interest_orientation**Ôºà‰ª•ÂÖ¨ÂÖ±Âà©ÁõäÁÇ∫Â∞éÂêëÔºâ",
        "**critical_thinking_encouraged**Ôºà‰øÉÈÄ≤ÊâπÂà§ÊÄùËÄÉÔºâ",
        "**timely_relevance_and_timeless_insight**ÔºàÂ†±ÈÅìÂÖ∑ÊôÇÊïàÊÄßÂíåÈï∑ÈÅ†ÂïüÁôºÊÄßÔºâ",
        "**inclusive_language** (ÂåÖÂÆπÊÄßË™ûË®Ä)",
        "**representation_of_marginalized_groups** (Âº±Âã¢Áæ§È´îÊúâÂëàÁèæ)",
    ],
    "journalistic_demerits":[
        "**decontextualisation**ÔºàËÑ´Èõ¢Ë™ûÂ¢É/Áº∫‰πèÁ¥∞Á∑ªËÑàÁµ°Ôºâ",
        "**clickbait**ÔºàÊ®ôÈ°åÈª®Ôºâ",
        "**fear_mongering**ÔºàÊÉ°ÊÑèÂºïËµ∑Á§æÊúÉÊÅêÊÖåÔºâ",
        "**cherry_picking**ÔºàÈÅ∏ÊìáÊÄßËàâ‰æãÔºâ",
        "**loaded_language**ÔºàÊÉÖÁ∑íÊÄßÁî®Ë™ûÔºâ",
        "**conflation**Ôºà‰∏çÁï∂Ê∑∑Ê∑ÜÔºâ",
        "**lack_of_balance**ÔºàÁº∫‰πèÂπ≥Ë°°ËßÄÈªûÔºâ",
        "**overemphasis_on_profanity_and_insults**ÔºàÈÅéÂ∫¶ÊîæÂ§ßÁ≤ó‰øóË™ûË®ÄÊàñ‰∫∫Ë∫´ÊîªÊìäÔºâ",
        "**social_media_amplification_trap**ÔºàÁ§æÁæ§ÊîæÂ§ßÈô∑Èò±Ôºâ",
        "**nationalistic_framing**ÔºàÊ∞ëÊóè‰∏ªÁæ©Ê°ÜÊû∂Ôºâ",
        "**corporate_glorification**Ôºà‰ºÅÊ•≠ÁæéÂåñÔºâ",
        "**overemphasis_on_glory**ÔºàÈÅéÂ∫¶Âº∑Ë™øÊàêÂ∞±Ôºâ",
        "**propagandistic_tone**ÔºàÂ§ßÂ§ñÂÆ£Ë™ûË™øÔºâ",
        "**overuse_of_statistics_without_verification**ÔºàÊï∏ÊìöÊø´Áî®ÊàñÊú™È©óË≠âÔºâ",
        "**no_critical_inquiry_or_accountability**ÔºàÁº∫‰πèÊâπÂà§ËàáË≤¨‰ªªËøΩÁ©∂Ôºâ",
        "**strategic_omission**ÔºàÁ≠ñÁï•ÊÄßÂøΩÁï•Ôºâ",
        "**anonymous_authority**Ôºà‰∏çÂÖ∑ÂêçÊ¨äÂ®ÅÔºâ",
        "**disproportionate_amplification_of_minor_incidents**ÔºàÊ¨°Ë¶Å‰∫ã‰ª∂ÁöÑÈÅéÂ∫¶ÊîæÂ§ßÔºâ",
        "**victimhood_framing**ÔºàÂèóÂÆ≥ËÄÖÊ°ÜÊû∂Ôºâ",
        "**heroic_framing**ÔºàËã±ÈõÑÊïò‰∫ãÔºâ",
        "**binary_framing**ÔºàÈùûÈªëÂç≥ÁôΩÊïò‰∫ãÔºâ",
        "**moral_judgment_framing**ÔºàÈÅìÂæ∑Âà§Êñ∑ÂåÖË£ùÔºâ",
        "**cultural_essentialism**ÔºàÊñáÂåñÊú¨Ë≥™Ë´ñÔºâ",
        "**traditional_values_shield**Ôºà‰∏ªÂºµÂÇ≥Áµ±ÂÉπÂÄº‰ΩúÊìãÁÆ≠ÁâåÔºâ",
        "**pre_criminal_framing**ÔºàÈ†êË®≠ÊúâÁΩ™Ôºâ"
        "**whataboutism**ÔºàÈÇ£ÂèàÊÄéÈ∫ºËæ¶‰∏ªÁæ©Ôºâ"
        "**pseudo_expertise** (ÂºïÁî®ÈùûÂ∞àÊ•≠‰∫∫Â£´‰ΩúÁÇ∫Ê¨äÂ®Å)"
        "**overpersonalisation** (ÈÅéÂ∫¶Âº∑Ë™øÂÄã‰∫∫Ë≤¨‰ªªÔºåÂøΩË¶ñÁµêÊßãÊÄßÂïèÈ°å)",
        "**false_balance**ÔºàËôõÂÅáÂπ≥Ë°°Ôºâ"
        "**false_equivalence**ÔºàÈåØË™§È°ûÊØîÔºâ",
        "**echoing_government_or_corporate_press_releases**ÔºàÂÉÖÈáçË§áÂÆòÊñπË™™Ê≥ïÔºâ",
        "**narrative_over_facts**ÔºàÊïò‰∫ã‰∏ªÂ∞éÔºå‰∫ãÂØ¶ÈÄÄ‰ΩçÔºâ"
    ],
    "reporting_style": [
        "he_said_she_said_reporting", "propagandistic_reporting", "investigative_reporting",
        "solutions_journalism", "feature_reporting", "advocacy_journalism", 
        "opinion_reporting", "sensationalist_reporting", "stenographic_reporting",
        "data_journalism", "explanatory_reporting"
    ]
}
journalistic_merits_list = "\n".join([f"- {tag}" for tag in ALLOWED_TAGS["journalistic_merits"]])
misguiding_tools_list = "\n".join([f"- {tag}" for tag in ALLOWED_TAGS["journalistic_demerits"]])
reporting_style = "\n".join([f"- {tag}" for tag in ALLOWED_TAGS["reporting_style"]])

# political standing
system_prompt = f"""
‰Ω†ÊòØ‰∏Ä‰ΩçÊñ∞ËÅûÂàÜÊûêÂä©ÁêÜÔºåÂ∞àÈñÄË≤†Ë≤¨Âà§Êñ∑Êñ∞ËÅûÊñáÁ´†‰∏≠Â§öÂ§ßÁ®ãÂ∫¶‰∏äÂ≠òÂú®‰ª•‰∏ãÁâπÂÆöÁöÑÊñ∞ËÅûÂÑ™ÈªûÂíåË™§Â∞éÊÄßÂ†±Â∞éÊäÄË°ìÔºå‰∏¶ÈáùÂ∞çÊØè‰∏ÄÈ†ÖÊèê‰æõÊ∏ÖÊ•ö„ÄÅÊúâÊ†πÊìöÁöÑË™™Êòé„ÄÇ

---

1.Ëã•ÊñáÁ´†Ê®ôÈ°åÂåÖÂê´„ÄåÊ®ôÈ°åÈª®ÔºèËÅ≥Âãï„ÄçÁâπÂæµÔºàÂ¶ÇË™áÂºµÂΩ¢ÂÆπ„ÄÅÊÅêÂöáÊÄßÊé™Ëæ≠„ÄÅÈÅéÂ∫¶ÁµïÂ∞çÂåñ„ÄÅË≥£ÈóúÂ≠êË™ûÂè•ÔºâÔºåË´ãÂú®Ëº∏Âá∫ JSON ÁöÑÊúÄ‰∏äÂ±§Âä†ÂÖ• "refined_title" Ê¨Ñ‰ΩçÔºåÊèê‰æõ‰∏ÄÂÄãÊõ¥Ê∫ñÁ¢∫„ÄÅÂÖãÂà∂‰∏îËàáÂÖßÊñá‰∏ÄËá¥ÁöÑÊ®ôÈ°åÔºõËã•ÁÑ°Ê≠§ÂïèÈ°åÔºå"refined_title" Ë´ãÂ°´ null„ÄÇË´ã‰ª•ÁπÅÈ´î‰∏≠ÊñáÊí∞ÂØ´ refined_title„ÄÇ

2.Ë´ã‰æùÊìö‰ª•‰∏ãÂÖ©ÁµÑÊ®ôÁ±§ÈÄ≤Ë°åÂàÜÊûêÔºö

2a.### üìå Ë™§Â∞éÊâãÊ≥ïÔºàjournalistic demeritsÔºâ
ÈÄô‰∫õÊòØÂèØËÉΩË™§Â∞éËÆÄËÄÖÁöÑÂ†±Â∞éÊäÄË°ìÔºåÂè™Ê®ôÁ§∫ÊúâÈóúÊàñÂá∫ÁèæÈÅéÁöÑÔºö

{misguiding_tools_list}

2b.### üìå Êñ∞ËÅûÂÑ™ÈªûÔºàjournalistic meritsÔºâ
ÈÄô‰∫õÊòØËÉΩÊèêÂçáÊñ∞ËÅûÂìÅË≥™ÁöÑÁâπÂæµÔºåË´ãÂà§Êñ∑ÊòØÂê¶ÊúâÂÖ∑È´îÈ´îÁèæÔºö

{journalistic_merits_list}

3.### üìå Êñ∞ËÅûÂ†±ÈÅìÈ¢®Ê†ºÔºàreporting stylesÔºâ
{reporting_style}

4.### üìå Êñ∞ËÅûÂ†±ÈÅìÁõÆÁöÑÔºàreporting intentionÔºâ
Ëá™Áî±ÁôºÊèÆ
---

### ‚ö†Ô∏è Ë´ãÊ≥®ÊÑèÔºö
- **ÂÉÖÂàóÂá∫ÂØ¶ÈöõÂú®ÊñáÁ´†‰∏≠Âá∫ÁèæÁöÑÊ®ôÁ±§**ÔºàÁÑ°Ë´ñÊòØË™§Â∞éÂ∑•ÂÖ∑ÊàñÊñ∞ËÅûÂÉπÂÄºÁâπÂæµÔºâ„ÄÇ
- ÊØè‰∏ÄÈ†ÖÊ®ôË®ªË´ãÊèê‰æõÂÖ∑È´îÊèèËø∞ËàáË©ï‰º∞Á®ãÂ∫¶Ôºå‰∏¶ÂºïÁî®ÊñáÁ´†‰∏≠ÁöÑÂ≠óË©û„ÄÅÂè•Â≠êÊàñÊÆµËêΩ‰ΩúÁÇ∫‰æùÊìö„ÄÇ

---

### Ë´ãÈáùÂ∞çÊØè‰∏ÄÈ†ÖË™§Â∞éÂ∑•ÂÖ∑Ôºå‰æù‰∏ãÂàóÊ†ºÂºèËº∏Âá∫Ôºö
{{
  "refined_title": "Ëã•ÈúÄË¶Å‰øÆË®ÇÂâáÂ°´ÂÖ•‰øÆË®ÇÂæåÊ®ôÈ°åÔºõÂê¶ÂâáÁÇ∫ null",
  "journalistic_demerits": {{
    "decontextualisation": {{
      "description": "Ë´ãÁî®ÁπÅÈ´î‰∏≠ÊñáÂÖ∑È´îË©≥Á¥∞ÊèèËø∞Ë©≤Ë™§Â∞éÊäÄË°ìÂú®ÊñáÁ´†‰∏≠ÊòØÂê¶Âá∫ÁèæÔºå‰ª•ÂèäÁî®ÊñáÁ´†‰∏≠ÁöÑÂÖ∑È´îÁî®Ë©ûËß£ÈáãÂá∫ÁèæÁöÑÊñπÂºè„ÄÅÁ®ãÂ∫¶ËàáË™ûÂ¢ÉÔºå‰∏¶ÈúÄË¶ÅÊ∫ñÁ¢∫ÂºïÁî®‰∫∫„ÄÅÁâ©Âíå‰∫ãË™™Êòé„ÄÇ",
      "degree": "not applicable / low / moderate / high"
    }},
    ...
  }},
  "journalistic_merits": {{
    "multiple_perspectives": {{
      "description": "Ë´ãÁî®ÁπÅÈ´î‰∏≠ÊñáÂÖ∑È´îË©≥Á¥∞ÊèèËø∞Ë©≤Êñ∞ËÅûÂÑ™ÈªûÂú®ÊñáÁ´†‰∏≠ÊòØÂê¶Âá∫ÁèæÔºå‰ª•ÂèäÁî®ÊñáÁ´†‰∏≠ÁöÑÂÖ∑È´îÁî®Ë©ûËß£ÈáãÂá∫ÁèæÁöÑÊñπÂºè„ÄÅÁ®ãÂ∫¶ËàáË™ûÂ¢ÉÔºå‰∏¶ÈúÄË¶ÅÊ∫ñÁ¢∫ÂºïÁî®‰∫∫„ÄÅÁâ©Âíå‰∫ãÊòé„ÄÇ",
      "degree": "not applicable / low / moderate / high"
    }},
    ...
  }},
  "reporting_style": [ÈÅ∏Áî®ÈÅ©Áî®ÁöÑÂ†±ÈÅìÈ¢®Ê†º, ...],
  "reporting_intention": [Á∞°Áü≠Ê∫ñÁ¢∫ÊåáÂá∫1-3ÂÄãÂ†±ÈÅìÁõÆÁöÑÂíåÁî®ÊÑè, ...],
}}
"""

async def classifiy_article(article: NewsEntity):
    user_prompt = f"""Ë´ãÂàÜÊûê‰ª•‰∏ãÊñ∞ËÅûÊñáÁ´†Ôºå‰∏¶‰æù system prompt ÁöÑÊ†ºÂºèËàáË¶èÂâáËº∏Âá∫ÁµêÊßãÂåñ JSON ÂàÜÊûêÁµêÊûú:

--- ARTICLE START ---
Ê®ôÈ°åÔºö{article.title}
ÂÖßÊñá: {article.content}
--- ARTICLE END ---
"""

    async with _llm_semaphore:
        print("‚≠êÔ∏è Trying to call the API!")
        try:
            response = client.chat.completions.create(
                model="Qwen/Qwen3-235B-A22B-Instruct-2507-tput",
                messages=[
                    {"role": "system", "content": system_prompt.strip()},
                    {"role": "user", "content": user_prompt.strip()}
                ],
                temperature=0.6
            )
            print("response:",response)
            content = response.choices[0].message.content
            if not content or not isinstance(content, str) or not content.strip():
                raise ValueError("Empty content from LLM")
        except Exception as e:
            print("LLM call failed or empty content:", repr(e))
            data = _empty_analysis()
        else:
            try:
                data = json.loads(content)
                if not isinstance(data, dict):
                    # Some models may wrap in a list; salvage first object
                    if isinstance(data, list) and data and isinstance(data[0], dict):
                        data = data[0]
                    else:
                        raise ValueError("Parsed JSON is not an object")
            except Exception as parse_err:
                # Last-resort salvage
                try:
                    start = content.find("{")
                    end = content.rfind("}") + 1
                    candidate = content[start:end] if (start != -1 and end > start) else "{}"
                    data = json.loads(candidate)
                    if not isinstance(data, dict):
                        raise ValueError("Salvaged JSON is not an object")
                except Exception:
                    print("‚ö†Ô∏è Failed to parse JSON. Raw output:")
                    print(content)
                    print("Parse error:", repr(parse_err))
                    data = _empty_analysis()

    # Post-processing defaults
    if not isinstance(data, dict):
        data = _empty_analysis()

    print("data:",data)
    data.setdefault("refined_title", None)
    data.setdefault("journalistic_demerits", {})
    data.setdefault("journalistic_merits", {})
    data.setdefault("reporting_style", [])
    data.setdefault("reporting_intention", [])

    def _standardize_section(section_dict):
        out = {}
        if not isinstance(section_dict, dict):
            section_dict = {}
        for k, v in section_dict.items():
            key = _normalize_key(k if isinstance(k, str) else str(k))
            v = v or {}
            desc = (v.get("description") or "").strip()
            degree = (v.get("degree") or "").strip().lower()
            if degree not in {"not applicable", "low", "moderate", "high"}:
                degree = "not applicable" if not desc else "low"
            out[key] = {"description": desc, "degree": degree}
        return out

    data["journalistic_demerits"] = _standardize_section(data.get("journalistic_demerits"))
    data["journalistic_merits"] = _standardize_section(data.get("journalistic_merits"))

    def _as_str_list(x):
        if x is None:
            return []
        if isinstance(x, str):
            s = x.strip()
            return [s] if s else []
        if isinstance(x, list):
            out = []
            for i in x:
                s = str(i).strip()
                if s:
                    out.append(s)
            return out
        # Some models return dict with boolean flags; flatten truthy keys
        if isinstance(x, dict):
            return [str(k) for k, v in x.items() if v]
        return []

    data["reporting_style"] = _as_str_list(data.get("reporting_style"))
    data["reporting_intention"] = _as_str_list(data.get("reporting_intention"))

    # Update entity safely
    if isinstance(article, NewsEntity):
        refined_title = data.get("refined_title")
        article.refined_title = refined_title.strip() if isinstance(refined_title, str) and refined_title.strip() else None

        if hasattr(article, "journalistic_demerits"):
            article.journalistic_demerits = data["journalistic_demerits"]
        if hasattr(article, "journalistic_merits"):
            article.journalistic_merits = data["journalistic_merits"]
        if hasattr(article, "reporting_style"):
            article.reporting_style = list(data["reporting_style"])  # ensure list
        if hasattr(article, "reporting_intention"):
            article.reporting_intention = list(data["reporting_intention"])

    return dict(data)