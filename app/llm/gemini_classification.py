import os
import asyncio
from typing import Any, Dict, List, Optional, Tuple
import google.generativeai as genai

from util.jsonSanitize import safe_parse_json, is_retriable_error_msg
from scrapers.news import AssessmentItem

ALLOWED_TAGS = {
    "journalistic_merits": [
        "**multiple_perspectives**ï¼ˆå¤šå…ƒè§€é»ï¼‰",
        "**logical_flow**ï¼ˆé‚è¼¯æ¸…æ™°ï¼‰",
        "**use_of_real_world_examples**ï¼ˆå¯¦ä¾‹å…·é«”ï¼‰",
        "**constructive_criticism**ï¼ˆå…·å»ºè¨­æ€§æ‰¹è©•ï¼‰",
        "**avoidance_of_nationalism_or_populism**ï¼ˆé¿å…æ°‘æ—ä¸»ç¾©æˆ–æ°‘ç²¹ä¸»ç¾©ï¼‰",
        "**source_transparency**ï¼ˆæ¶ˆæ¯ä¾†æºé€æ˜ï¼‰",
        "**clarification_of_uncertainty**ï¼ˆæ¾„æ¸…ä¸ç¢ºå®šæ€§ï¼‰",
        "**background_context**ï¼ˆèƒŒæ™¯è„ˆçµ¡å……åˆ†ï¼‰",
        "**transparency_of_process(å ±å°éç¨‹é€æ˜)",
        "**depth_of_analysis** (åˆ†ææ·±å…¥)",
        "**engagement_with_complexity** (æœ‰è™•ç†è­°é¡Œçš„è¤‡é›œæ€§)",
        "**local_relevance_and_contextualization** (åœ¨åœ°è„ˆçµ¡åŒ–èˆ‡é—œè¯æ€§)",
        "**independence_from_power** (å ±å°ç¨ç«‹æ€§å¼·)",
        "**clarity_of_purpose** (å ±å°ç›®çš„æ˜ç¢º)",
        "**accountability_framing**ï¼ˆæŒä»½è€…è²¬ä»»æ­¸å±¬æ˜ç¢ºï¼‰",
        "**ethical_reporting**ï¼ˆå…·å€«ç†æ„è­˜çš„å ±å°ï¼‰",
        "**use_of_data**ï¼ˆå–„ç”¨æ•¸æ“šï¼‰",
        "**cultural_humility**ï¼ˆå±•ç¾æ–‡åŒ–è¬™éœï¼‰",
        "**centering_affected_voices**ï¼ˆå‡¸é¡¯ç•¶äº‹è€…è§€é»ï¼‰",
        "**readability**ï¼ˆè¡¨é”æ˜“æ‡‚ï¼‰",
        "**headline_reflects_content**ï¼ˆæ¨™é¡Œèˆ‡å…§æ–‡ä¸€è‡´ï¼‰",
        "**public_interest_orientation**ï¼ˆä»¥å…¬å…±åˆ©ç›Šç‚ºå°å‘ï¼‰",
        "**critical_thinking_encouraged**ï¼ˆä¿ƒé€²æ‰¹åˆ¤æ€è€ƒï¼‰",
        "**timely_relevance_and_timeless_insight**ï¼ˆå ±é“å…·æ™‚æ•ˆæ€§å’Œé•·é å•Ÿç™¼æ€§ï¼‰"
    ],
    "journalistic_demerits": [
        "**decontextualisation**ï¼ˆè„«é›¢èªå¢ƒ/ç¼ºä¹ç´°ç·»è„ˆçµ¡ï¼‰",
        "**clickbait**ï¼ˆæ¨™é¡Œé»¨ï¼‰",
        "**fear_mongering**ï¼ˆæƒ¡æ„å¼•èµ·ç¤¾æœƒææ…Œï¼‰",
        "**cherry_picking**ï¼ˆé¸æ“‡æ€§èˆ‰ä¾‹ï¼‰",
        "**loaded_language**ï¼ˆæƒ…ç·’æ€§ç”¨èªï¼‰",
        "**conflation**ï¼ˆä¸ç•¶æ··æ·†ï¼‰",
        "**lack_of_balance**ï¼ˆç¼ºä¹å¹³è¡¡è§€é»ï¼‰",
        "**overemphasis_on_profanity_and_insults**ï¼ˆéåº¦æ”¾å¤§ç²—ä¿—èªè¨€æˆ–äººèº«æ”»æ“Šï¼‰",
        "**social_media_amplification_trap**ï¼ˆç¤¾ç¾¤æ”¾å¤§é™·é˜±ï¼‰",
        "**nationalistic framing**ï¼ˆæ°‘æ—ä¸»ç¾©æ¡†æ¶ï¼‰",
        "**corporate_glorification**ï¼ˆä¼æ¥­ç¾åŒ–ï¼‰",
        "**overemphasis_on_glory**ï¼ˆéåº¦å¼·èª¿æˆå°±ï¼‰",
        "**propagandistic_tone**ï¼ˆå¤§å¤–å®£èªèª¿ï¼‰",
        "**overuse_of_statistics_without_verification**ï¼ˆæ•¸æ“šæ¿«ç”¨æˆ–æœªé©—è­‰ï¼‰",
        "**no_critical_inquiry_or_accountability**ï¼ˆç¼ºä¹æ‰¹åˆ¤èˆ‡è²¬ä»»è¿½ç©¶ï¼‰",
        "**strategic_omission**ï¼ˆç­–ç•¥æ€§å¿½ç•¥ï¼‰",
        "**anonymous_authority**ï¼ˆä¸å…·åæ¬Šå¨ï¼‰",
        "**minor_incident_magnification**ï¼ˆå°äº‹ä»¶èª‡å¤§ï¼‰",
        "**victimhood_framing**ï¼ˆå—å®³è€…æ¡†æ¶ï¼‰",
        "**heroic_framing**ï¼ˆè‹±é›„æ•˜äº‹ï¼‰",
        "**binary_framing**ï¼ˆéé»‘å³ç™½æ•˜äº‹ï¼‰",
        "**moral_judgment_framing**ï¼ˆé“å¾·åˆ¤æ–·åŒ…è£ï¼‰",
        "**cultural_essentialism**ï¼ˆæ–‡åŒ–æœ¬è³ªè«–ï¼‰",
        "**traditional_values_shield**ï¼ˆä¸»å¼µå‚³çµ±åƒ¹å€¼ä½œæ“‹ç‰Œï¼‰",
        "**pre_criminal_framing**ï¼ˆé è¨­æœ‰ç½ªï¼‰"
    ],
    "reporting_style": [
        "he_said_she_said_reporting",
        "propagandistic_reporting",
        "investigative_reporting",
        "solutions_journalism",
        "feature_reporting",
        "advocacy_journalism",
        "opinion_reporting",
        "sensationalist_reporting",
        "stenographic_reporting",
        "data_journalism",
        "explanatory_reporting",
        "entertainment_reporting",
        "infotainment_reporting",
        "patriotic_reporting"
    ]
}

def _build_clean_allowed_set(raw_tags):
    clean = set()
    for t in raw_tags:
        core = t.split("**")[1].strip() if (isinstance(t, str) and t.startswith("**") and t.count("**") >= 2) else t
        core = core.replace("ï¼ˆ", " ").replace("ï¼‰", " ").strip()
        clean.add(core)
    return clean

_CLEAN_ALLOWED_DEMERITS = _build_clean_allowed_set(ALLOWED_TAGS["journalistic_demerits"])
_CLEAN_ALLOWED_MERITS = _build_clean_allowed_set(ALLOWED_TAGS["journalistic_merits"])

def _clean_key(key: str) -> str:
    if not isinstance(key, str):
        return ""
    k = key.strip()
    if k.startswith("**") and k.count("**") >= 2:
        k = k.split("**")[1].strip()
    return k.replace("ï¼ˆ", " ").replace("ï¼‰", " ").strip()

def _normalize_degree(val: str) -> str:
    if not isinstance(val, str):
        return "low"
    v = val.strip().lower()
    return v if v in {"low", "moderate", "high"} else "low"

def _coerce_float_0_1(x) -> Optional[float]:
    try:
        f = float(x)
        f = 0.0 if f < 0 else (1.0 if f > 1 else f)
        return round(f, 2)
    except Exception:
        return None

system_prompt_template = """
ä½ æ˜¯ä¸€ä½æ–°èåˆ†æåŠ©ç†ï¼Œå°ˆé–€è² è²¬åˆ¤æ–·æ–°èæ–‡ç« ä¸­å¤šå¤§ç¨‹åº¦ä¸Šå­˜åœ¨ä»¥ä¸‹ç‰¹å®šçš„æ–°èå„ªé»å’Œèª¤å°æ€§å ±å°æŠ€è¡“ï¼Œä¸¦é‡å°æ¯ä¸€é …æä¾›æ¸…æ¥šã€æœ‰æ ¹æ“šçš„èªªæ˜ã€‚

---

1.è«‹ä¾æ“šä»¥ä¸‹å…©çµ„æ¨™ç±¤é€²è¡Œåˆ†æï¼š

1a.### ğŸ“Œ èª¤å°æ‰‹æ³•ï¼ˆjournalistic_demeritsï¼‰
é€™äº›æ˜¯å¯èƒ½èª¤å°è®€è€…çš„å ±å°æŠ€è¡“ï¼Œåªæ¨™ç¤ºæœ‰é—œæˆ–å‡ºç¾éçš„ï¼š

{misguiding_tools_list}

1b.### ğŸ“Œ æ–°èå„ªé»ï¼ˆjournalistic_meritsï¼‰
é€™äº›æ˜¯èƒ½æå‡æ–°èå“è³ªçš„ç‰¹å¾µï¼Œè«‹åˆ¤æ–·æ˜¯å¦æœ‰å…·é«”é«”ç¾ï¼š

{journalistic_merits_list}

2.### ğŸ“Œ æ–°èå ±é“é¢¨æ ¼ï¼ˆreporting_styleï¼‰
{reporting_style_list}

3.### ğŸ“Œ æ–°èå ±é“ç›®çš„ï¼ˆreporting_intentionï¼‰
è‡ªç”±ç™¼æ®ï¼Œè«‹ç”¨æœ€å¤š10å­—æŒ‡å‡º1-3å€‹å ±é“ç›®çš„ã€‚

---

### âš ï¸ è«‹æ³¨æ„ï¼š
- **åƒ…åˆ—å‡ºå¯¦éš›åœ¨æ–‡ç« ä¸­å‡ºç¾çš„æ¨™ç±¤**ï¼ˆç„¡è«–æ˜¯èª¤å°å·¥å…·æˆ–æ–°èåƒ¹å€¼ç‰¹å¾µï¼‰ã€‚
- æ¯ä¸€é …æ¨™è¨»è«‹æä¾›å…·é«”æè¿°èˆ‡è©•ä¼°ç¨‹åº¦ï¼Œä¸¦å¼•ç”¨æ–‡ç« ä¸­çš„å­—è©ã€å¥å­æˆ–æ®µè½ä½œç‚ºä¾æ“šã€‚
- è«‹è¼¸å‡ºä»¥ä¸‹æ ¼å¼çš„æ¨™æº– JSONï¼Œä¸è¦åŒ…å« Markdown æˆ–å…¶ä»–èªªæ˜æ–‡å­—ã€‚
- è«‹ä¾æ“šå‡ºç¾é »ç‡ã€èªæ°£å¼·åº¦ã€ç¯‡å¹…æ¯”é‡èˆ‡å°è®€è€…å½±éŸ¿ï¼Œåˆ¤æ–·æ¯å€‹æ¨™ç±¤çš„ç¨‹åº¦ï¼ˆdegreeï¼‰ï¼Œä¸¦ä½¿ç”¨ä»¥ä¸‹åˆ†ç´šï¼š
  - lowï¼šåƒ…å‡ºç¾ä¸€æ¬¡æˆ–èªæ°£è¼•å¾®ï¼Œå°æ•´é«”å½±éŸ¿æ¥µä½ã€‚
  - moderateï¼šä¸­ç­‰é »ç‡æˆ–ç¯‡å¹…ï¼Œå°å ±å°ç†è§£é€ æˆæ˜é¡¯å½±éŸ¿ã€‚
  - highï¼šåè¦†å‡ºç¾æˆ–ç‚ºä¸»å°æ•˜äº‹ï¼Œé¡¯è‘—å½±éŸ¿å ±å°å®¢è§€æ€§èˆ‡åˆ¤æ–·ã€‚

---
{{
  "journalistic_demerits": {{
    "decontextualisation": {{
      "description": "è«‹ç”¨ç¹é«”ä¸­æ–‡å…·é«”è©³ç´°æè¿°è©²èª¤å°æŠ€è¡“åœ¨æ–‡ç« ä¸­æ˜¯å¦å‡ºç¾ï¼Œä»¥åŠç”¨æ–‡ç« ä¸­çš„å…·é«”ç”¨è©è§£é‡‹å‡ºç¾çš„æ–¹å¼ã€ç¨‹åº¦èˆ‡èªå¢ƒï¼Œä¸¦éœ€è¦æº–ç¢ºå¼•ç”¨äººã€ç‰©å’Œäº‹èªªæ˜ã€‚",
      "degree": "low / moderate / high"
    }},
    ...
  }},
  "journalistic_merits": {{
    "multiple_perspectives": {{
      "description": "è«‹ç”¨ç¹é«”ä¸­æ–‡å…·é«”è©³ç´°æè¿°è©²æ–°èå„ªé»åœ¨æ–‡ç« ä¸­æ˜¯å¦å‡ºç¾ï¼Œä»¥åŠç”¨æ–‡ç« ä¸­çš„å…·é«”ç”¨è©è§£é‡‹å‡ºç¾çš„æ–¹å¼ã€ç¨‹åº¦èˆ‡èªå¢ƒï¼Œä¸¦éœ€è¦æº–ç¢ºå¼•ç”¨äººã€ç‰©å’Œäº‹æ˜ã€‚",
      "degree": "low / moderate / high"
    }},
    ...
  }},
  "reporting_style": ["é¸ç”¨é©ç”¨çš„å ±é“é¢¨æ ¼", ...],
  "reporting_intention": ["ç”¨æœ€å¤š10å­—æŒ‡å‡ºå ±é“ç›®çš„", ...]
}}
"""

def _lists_for_prompt():
    jm = "\n".join([f"- {t}" for t in ALLOWED_TAGS["journalistic_merits"]])
    jd = "\n".join([f"- {t}" for t in ALLOWED_TAGS["journalistic_demerits"]])
    rs = "\n".join([f"- {t}" for t in ALLOWED_TAGS["reporting_style"]])
    return jm, jd, rs

class GeminiArticleClassifier:
    def __init__(self):
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise RuntimeError("GOOGLE_API_KEY not set")
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(os.getenv("GEMINI_MODEL", "models/gemini-2.5-flash-lite"))
        jm, jd, rs = _lists_for_prompt()
        self.system_prompt = system_prompt_template.format(
            misguiding_tools_list=jd,
            journalistic_merits_list=jm,
            reporting_style_list=rs
        )

    async def analyze(self, article_text: str, max_retries: int = 3) -> Dict[str, Any]:
        delay = 0.8
        user_prompt = f"""è«‹åˆ†æä»¥ä¸‹æ–°èæ–‡ç« ï¼Œä¸¦ä¾ system prompt çš„æ ¼å¼èˆ‡è¦å‰‡è¼¸å‡ºçµæ§‹åŒ– JSON åˆ†æçµæœï¼š

--- ARTICLE START ---
{article_text.strip()}
--- ARTICLE END ---
"""
        for attempt in range(max_retries):
            try:
                chat = self.model.start_chat(history=[{"role": "user", "parts": [self.system_prompt.strip()]}])
                response = chat.send_message(user_prompt.strip())
                data = safe_parse_json(response.text)
                return data
            except Exception as e:
                msg = str(e)
                if is_retriable_error_msg(msg) and attempt < max_retries - 1:
                    await asyncio.sleep(delay)
                    delay = min(delay * 2, 6.0)
                    continue
                raise

    # Extraction helpers exposed so the service layer can reuse consistent logic
    def extract_clickbait(self, data: dict) -> Optional[dict]:
        cb = data.get("clickbait")
        if not isinstance(cb, dict):
            rt = data.get("refined_title")
            if isinstance(rt, str) and rt.strip():
                return {"confidence": None, "explanation": None, "refined_title": rt.strip()}
            return None
        conf = self._coerce_float_0_1(cb.get("confidence"))
        exp = cb.get("explanation") if isinstance(cb.get("explanation"), str) and cb.get("explanation").strip() else None
        rt = cb.get("refined_title") if isinstance(cb.get("refined_title"), str) and cb.get("refined_title").strip() else None
        if conf is None and not exp and not rt:
            return None
        return {"confidence": conf, "explanation": exp.strip() if exp else None, "refined_title": rt.strip() if rt else None}

    def extract_reporting_style(self, data: dict) -> List[str]:
        rs = data.get("reporting_style", [])
        if not isinstance(rs, list):
            return []
        allowed = set(ALLOWED_TAGS["reporting_style"])
        return [t for t in rs if isinstance(t, str) and t in allowed]

    def extract_reporting_intention(self, data: dict) -> List[str]:
        ri = data.get("reporting_intention", [])
        if not isinstance(ri, list):
            return []
        out = []
        for x in ri:
            if isinstance(x, (str, int, float)):
                sx = str(x).strip().strip("ã€Œã€\"'")
                if sx:
                    out.append(sx[:10])
            if len(out) >= 3:
                break
        return out

    def extract_tagged_section(self, data: dict, key: str) -> Dict[str, AssessmentItem]:
        raw = data.get(key, {})
        out: Dict[str, AssessmentItem] = {}
        if not isinstance(raw, dict):
            return out
        for k, v in raw.items():
            if not isinstance(v, dict):
                continue
            clean_key = _clean_key(k)
            if key == "journalistic_demerits" and clean_key.lower() == "clickbait":
                # Allow service layer to decide; default keeps it. Service may strip.
                pass
            if clean_key not in _CLEAN_ALLOWED_DEMERITS.union(_CLEAN_ALLOWED_MERITS):
                # Only accept allowed tags
                if key == "journalistic_demerits" and clean_key not in _CLEAN_ALLOWED_DEMERITS:
                    continue
                if key == "journalistic_merits" and clean_key not in _CLEAN_ALLOWED_MERITS:
                    continue
            desc = v.get("description", "")
            deg = v.get("degree", "")
            if isinstance(desc, str) and desc.strip():
                if isinstance(deg, str) and deg.strip().lower() == "not applicable":
                    continue
                out[clean_key] = {"description": desc.strip(), "degree": _normalize_degree(deg)}
        return out

    def validate_schema(self, d: dict) -> Optional[str]:
        if "reporting_style" in d and not isinstance(d["reporting_style"], list):
            return "'reporting_style' must be a list"
        if "reporting_intention" in d and not isinstance(d["reporting_intention"], list):
            return "'reporting_intention' must be a list"
        for k in ("journalistic_demerits", "journalistic_merits"):
            if k in d and not isinstance(d[k], dict):
                return f"'{k}' must be an object"
        return None

    @staticmethod
    def _coerce_float_0_1(x) -> Optional[float]:
        try:
            f = float(x)
            f = 0.0 if f < 0 else (1.0 if f > 1 else f)
            return round(f, 2)
        except Exception:
            return None