import asyncio
import re
from typing import Dict, List, Optional
from together import Together
import json
import os
from dotenv import load_dotenv
import google.generativeai as genai
from app.modals.newsEntity import NewsEntity
from scrapers.news import AssessmentItem

load_dotenv()
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
model = genai.GenerativeModel("models/gemini-2.5-flash-lite")  # or replace with latest model name
# LLAMA:meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
# Alibaba: Qwen/Qwen2.5-7B-Instruct-Turbo

ALLOWED_TAGS = {
    "journalistic_merits": [
        "**multiple_perspectives**ÔºàÂ§öÂÖÉËßÄÈªûÔºâ",
        "**logical_flow**ÔºàÈÇèËºØÊ∏ÖÊô∞Ôºâ",
        "**use_of_real_world_examples**ÔºàÂØ¶‰æãÂÖ∑È´îÔºâ",
        "**constructive_criticism**ÔºàÂÖ∑Âª∫Ë®≠ÊÄßÊâπË©ïÔºâ",
        "**avoidance_of_nationalism_or_populism**ÔºàÈÅøÂÖçÊ∞ëÊóè‰∏ªÁæ©ÊàñÊ∞ëÁ≤π‰∏ªÁæ©Ôºâ",
        "**source_transparency**ÔºàÊ∂àÊÅØ‰æÜÊ∫êÈÄèÊòéÔºâ",
        "**clarification_of_uncertainty**ÔºàÊæÑÊ∏Ö‰∏çÁ¢∫ÂÆöÊÄßÔºâ",
        "**background_context**ÔºàËÉåÊôØËÑàÁµ°ÂÖÖÂàÜÔºâ",
        "**transparency_of_process(Â†±Â∞éÈÅéÁ®ãÈÄèÊòé)",
        "**depth_of_analysis** (ÂàÜÊûêÊ∑±ÂÖ•)",
        "**engagement_with_complexity** (ÊúâËôïÁêÜË≠∞È°åÁöÑË§áÈõúÊÄß)",
        "**local_relevance_and_contextualization** (Âú®Âú∞ËÑàÁµ°ÂåñËàáÈóúËÅØÊÄß)",
        "**independence_from_power** (Â†±Â∞éÁç®Á´ãÊÄßÂº∑)",
        "**clarity_of_purpose** (Â†±Â∞éÁõÆÁöÑÊòéÁ¢∫)",
        "**accountability_framing**ÔºàÊåÅ‰ªΩËÄÖË≤¨‰ªªÊ≠∏Â±¨ÊòéÁ¢∫Ôºâ",
        "**ethical_reporting**ÔºàÂÖ∑ÂÄ´ÁêÜÊÑèË≠òÁöÑÂ†±Â∞éÔºâ",
        "**use_of_data**ÔºàÂñÑÁî®Êï∏ÊìöÔºâ",
        "**cultural_humility**ÔºàÂ±ïÁèæÊñáÂåñË¨ôÈÅúÔºâ",
        "**centering_affected_voices**ÔºàÂá∏È°ØÁï∂‰∫ãËÄÖËßÄÈªûÔºâ",
        "**readability**ÔºàË°®ÈÅîÊòìÊáÇÔºâ",
        "**headline_reflects_content**ÔºàÊ®ôÈ°åËàáÂÖßÊñá‰∏ÄËá¥Ôºâ",
        "**public_interest_orientation**Ôºà‰ª•ÂÖ¨ÂÖ±Âà©ÁõäÁÇ∫Â∞éÂêëÔºâ",
        "**critical_thinking_encouraged**Ôºà‰øÉÈÄ≤ÊâπÂà§ÊÄùËÄÉÔºâ",
        "**timely_relevance_and_timeless_insight**ÔºàÂ†±ÈÅìÂÖ∑ÊôÇÊïàÊÄßÂíåÈï∑ÈÅ†ÂïüÁôºÊÄßÔºâ"
    ],
    "journalistic_demerits":[
        "**decontextualisation**ÔºàËÑ´Èõ¢Ë™ûÂ¢É/Áº∫‰πèÁ¥∞Á∑ªËÑàÁµ°Ôºâ",
        "**clickbait**ÔºàÊ®ôÈ°åÈª®Ôºâ",
        "**fear-mongering**ÔºàÊÉ°ÊÑèÂºïËµ∑Á§æÊúÉÊÅêÊÖåÔºâ",
        "**cherry-picking**ÔºàÈÅ∏ÊìáÊÄßËàâ‰æãÔºâ",
        "**loaded language**ÔºàÊÉÖÁ∑íÊÄßÁî®Ë™ûÔºâ",
        "**conflation**Ôºà‰∏çÁï∂Ê∑∑Ê∑ÜÔºâ",
        "**lack of balance**ÔºàÁº∫‰πèÂπ≥Ë°°ËßÄÈªûÔºâ",
        "**overemphasis on profanity and insults**ÔºàÈÅéÂ∫¶ÊîæÂ§ßÁ≤ó‰øóË™ûË®ÄÊàñ‰∫∫Ë∫´ÊîªÊìäÔºâ",
        "**social media amplification trap**ÔºàÁ§æÁæ§ÊîæÂ§ßÈô∑Èò±Ôºâ",
        "**nationalistic framing**ÔºàÊ∞ëÊóè‰∏ªÁæ©Ê°ÜÊû∂Ôºâ",
        "**corporate glorification**Ôºà‰ºÅÊ•≠ÁæéÂåñÔºâ",
        "**overemphasis on glory**ÔºàÈÅéÂ∫¶Âº∑Ë™øÊàêÂ∞±Ôºâ",
        "**propagandistic tone**ÔºàÂ§ßÂ§ñÂÆ£Ë™ûË™øÔºâ",
        "**overuse of statistics without verification**ÔºàÊï∏ÊìöÊø´Áî®ÊàñÊú™È©óË≠âÔºâ",
        "**no critical inquiry or accountability**ÔºàÁº∫‰πèÊâπÂà§ËàáË≤¨‰ªªËøΩÁ©∂Ôºâ",
        "**strategic omission**ÔºàÁ≠ñÁï•ÊÄßÂøΩÁï•Ôºâ",
        "**anonymous authority**Ôºà‰∏çÂÖ∑ÂêçÊ¨äÂ®ÅÔºâ",
        "**minor incident magnification**ÔºàÂ∞è‰∫ã‰ª∂Ë™áÂ§ßÔºâ",
        "**victimhood framing**ÔºàÂèóÂÆ≥ËÄÖÊ°ÜÊû∂Ôºâ",
        "**heroic framing**ÔºàËã±ÈõÑÊïò‰∫ãÔºâ",
        "**binary framing**ÔºàÈùûÈªëÂç≥ÁôΩÊïò‰∫ãÔºâ",
        "**moral judgment framing**ÔºàÈÅìÂæ∑Âà§Êñ∑ÂåÖË£ùÔºâ",
        "**cultural essentialism**ÔºàÊñáÂåñÊú¨Ë≥™Ë´ñÔºâ",
        "**traditional values shield**Ôºà‰∏ªÂºµÂÇ≥Áµ±ÂÉπÂÄº‰ΩúÊìãÁÆ≠ÁâåÔºâ",
        "**pre-criminal framing**ÔºàÈ†êË®≠ÊúâÁΩ™Ôºâ"
    ],
    "reporting_style": [
        "he_said_she_said_reporting", 
        "propagandistic_reporting", 
        "investigative_reporting",
        "solutions_journalism", 
        "feature_reporting", 
        "advocacy_journalism", 
        "opinion_reporting", 
        "sensationalist_reporting", 
        "stenographic_reporting",
        "data_journalism", 
        "explanatory_reporting"
    ]
}
journalistic_merits_list = "\n".join([f"- {tag}" for tag in ALLOWED_TAGS["journalistic_merits"]])
misguiding_tools_list = "\n".join([f"- {tag}" for tag in ALLOWED_TAGS["journalistic_demerits"]])
reporting_style = "\n".join([f"- {tag}" for tag in ALLOWED_TAGS["reporting_style"]])

# political standing
system_prompt = f"""
‰Ω†ÊòØ‰∏Ä‰ΩçÊñ∞ËÅûÂàÜÊûêÂä©ÁêÜÔºåÂ∞àÈñÄË≤†Ë≤¨Âà§Êñ∑Êñ∞ËÅûÊñáÁ´†‰∏≠Â§öÂ§ßÁ®ãÂ∫¶‰∏äÂ≠òÂú®‰ª•‰∏ãÁâπÂÆöÁöÑÊñ∞ËÅûÂÑ™ÈªûÂíåË™§Â∞éÊÄßÂ†±Â∞éÊäÄË°ìÔºå‰∏¶ÈáùÂ∞çÊØè‰∏ÄÈ†ÖÊèê‰æõÊ∏ÖÊ•ö„ÄÅÊúâÊ†πÊìöÁöÑË™™Êòé„ÄÇ

---

1.Ëã•ÊñáÁ´†Ê®ôÈ°åÂåÖÂê´„ÄåÊ®ôÈ°åÈª®ÔºèËÅ≥Âãï„ÄçÁâπÂæµÔºàÂ¶ÇË™áÂºµÂΩ¢ÂÆπ„ÄÅÊÅêÂöáÊÄßÊé™Ëæ≠„ÄÅÈÅéÂ∫¶ÁµïÂ∞çÂåñ„ÄÅË≥£ÈóúÂ≠êË™ûÂè•ÔºâÔºåË´ãÂú®Ëº∏Âá∫ JSON ÁöÑÊúÄ‰∏äÂ±§Âä†ÂÖ• "refined_title" Ê¨Ñ‰ΩçÔºåÊèê‰æõ‰∏ÄÂÄãÊõ¥Ê∫ñÁ¢∫„ÄÅÂÖãÂà∂‰∏îËàáÂÖßÊñá‰∏ÄËá¥ÁöÑÊ®ôÈ°åÔºõËã•ÁÑ°Ê≠§ÂïèÈ°åÔºå"refined_title" Ë´ãÂ°´ null„ÄÇË´ã‰ª•ÁπÅÈ´î‰∏≠ÊñáÊí∞ÂØ´ refined_title„ÄÇ

2.Ë´ã‰æùÊìö‰ª•‰∏ãÂÖ©ÁµÑÊ®ôÁ±§ÈÄ≤Ë°åÂàÜÊûêÔºö

2a.### üìå Ë™§Â∞éÊâãÊ≥ïÔºàjournalistic demeritsÔºâ
ÈÄô‰∫õÊòØÂèØËÉΩË™§Â∞éËÆÄËÄÖÁöÑÂ†±Â∞éÊäÄË°ìÔºåÂè™Ê®ôÁ§∫ÊúâÈóúÊàñÂá∫ÁèæÈÅéÁöÑÔºö

{misguiding_tools_list}

2b.### üìå Êñ∞ËÅûÂÑ™ÈªûÔºàjournalistic meritsÔºâ
ÈÄô‰∫õÊòØËÉΩÊèêÂçáÊñ∞ËÅûÂìÅË≥™ÁöÑÁâπÂæµÔºåË´ãÂà§Êñ∑ÊòØÂê¶ÊúâÂÖ∑È´îÈ´îÁèæÔºö

{journalistic_merits_list}

3.### üìå Êñ∞ËÅûÂ†±ÈÅìÈ¢®Ê†ºÔºàreporting stylesÔºâ
{reporting_style}

4.### üìå Êñ∞ËÅûÂ†±ÈÅìÁõÆÁöÑÔºàreporting intentionÔºâ
Ëá™Áî±ÁôºÊèÆ
---

### ‚ö†Ô∏è Ë´ãÊ≥®ÊÑèÔºö
- **ÂÉÖÂàóÂá∫ÂØ¶ÈöõÂú®ÊñáÁ´†‰∏≠Âá∫ÁèæÁöÑÊ®ôÁ±§**ÔºàÁÑ°Ë´ñÊòØË™§Â∞éÂ∑•ÂÖ∑ÊàñÊñ∞ËÅûÂÉπÂÄºÁâπÂæµÔºâ„ÄÇ
- ÊØè‰∏ÄÈ†ÖÊ®ôË®ªË´ãÊèê‰æõÂÖ∑È´îÊèèËø∞ËàáË©ï‰º∞Á®ãÂ∫¶Ôºå‰∏¶ÂºïÁî®ÊñáÁ´†‰∏≠ÁöÑÂ≠óË©û„ÄÅÂè•Â≠êÊàñÊÆµËêΩ‰ΩúÁÇ∫‰æùÊìö„ÄÇ
- Âè™È°ØÁ§∫ÈÅ©Áî®ÁöÑË™§Â∞éÊâãÊ≥ïÔºàjournalistic demeritsÔºâÂíåÊñ∞ËÅûÂÑ™ÈªûÔºàjournalistic meritsÔºâ, ‰ΩÜÂøÖÈ†àÈ°ØÁ§∫"refined_title", Êñ∞ËÅûÂ†±ÈÅìÈ¢®Ê†ºÔºàreporting stylesÔºâÂíåÊñ∞ËÅûÂ†±ÈÅìÁõÆÁöÑÔºàreporting intentionÔºâ
- Ëº∏Âá∫ÁØÑ‰æãÊ†ºÂºèÂøÖÈ†àÁÇ∫Ê®ôÊ∫ñ JSONÔºåÁõ¥Êé•Ëº∏Âá∫Á¥î JSON ÁµêÊßãÔºå‰∏çÈúÄË¶ÅÈ°çÂ§ñÂåÖË£ùÂú® content Ê¨Ñ‰Ωç‰∏ã„ÄÇ

---
{{
  "refined_title": "Ëã•ÈúÄË¶Å‰øÆË®ÇÂâáÂ°´ÂÖ•‰øÆË®ÇÂæåÊ®ôÈ°åÔºõÂê¶ÂâáÁÇ∫ null",
  "journalistic_demerits": {{
    "decontextualisation": {{
      "description": "Ë´ãÁî®ÁπÅÈ´î‰∏≠ÊñáÂÖ∑È´îË©≥Á¥∞ÊèèËø∞Ë©≤Ë™§Â∞éÊäÄË°ìÂú®ÊñáÁ´†‰∏≠ÊòØÂê¶Âá∫ÁèæÔºå‰ª•ÂèäÁî®ÊñáÁ´†‰∏≠ÁöÑÂÖ∑È´îÁî®Ë©ûËß£ÈáãÂá∫ÁèæÁöÑÊñπÂºè„ÄÅÁ®ãÂ∫¶ËàáË™ûÂ¢ÉÔºå‰∏¶ÈúÄË¶ÅÊ∫ñÁ¢∫ÂºïÁî®‰∫∫„ÄÅÁâ©Âíå‰∫ãË™™Êòé„ÄÇ",
      "degree": "low / moderate / high"
    }},
    ...
  }},
  "journalistic_merits": {{
    "multiple_perspectives": {{
      "description": "Ë´ãÁî®ÁπÅÈ´î‰∏≠ÊñáÂÖ∑È´îË©≥Á¥∞ÊèèËø∞Ë©≤Êñ∞ËÅûÂÑ™ÈªûÂú®ÊñáÁ´†‰∏≠ÊòØÂê¶Âá∫ÁèæÔºå‰ª•ÂèäÁî®ÊñáÁ´†‰∏≠ÁöÑÂÖ∑È´îÁî®Ë©ûËß£ÈáãÂá∫ÁèæÁöÑÊñπÂºè„ÄÅÁ®ãÂ∫¶ËàáË™ûÂ¢ÉÔºå‰∏¶ÈúÄË¶ÅÊ∫ñÁ¢∫ÂºïÁî®‰∫∫„ÄÅÁâ©Âíå‰∫ãÊòé„ÄÇ",
      "degree": "low / moderate / high"
    }},
    ...
  }},
  "reporting_style": [ÈÅ∏Áî®ÈÅ©Áî®ÁöÑÂ†±ÈÅìÈ¢®Ê†º, ...],
  "reporting_intention": [Á∞°Áü≠Ê∫ñÁ¢∫ÊåáÂá∫1-3ÂÄãÂ†±ÈÅìÁõÆÁöÑÂíåÁî®ÊÑè, ...],
}}
"""

print("system_prompt:",system_prompt)

class FieldError(ValueError):
    pass

def expect(condition: bool, path: str, message: str = ""):
    if not condition:
        raise FieldError(f"Field '{path}' invalid. {message}".strip())

def safe_parse_json(content: str):
    # ÂòóË©¶Âæû markdown Ê†ºÂºè‰∏≠ÊèêÂèñÁ¥î JSON ÂçÄÂ°ä
    match = re.search(r"```json\s*([\s\S]+?)\s*```", content)
    if not match:
        # Ëã•ÁÑ° markdown Ê®ôË®òÔºåÁõ¥Êé•ÂæûÁ¨¨‰∏ÄÂÄã { ÈñãÂßã
        match = re.search(r"\{[\s\S]+", content)
        if not match:
            raise ValueError("‚ö†Ô∏è ÁÑ°Ê≥ïÊâæÂà∞ JSON ÂçÄÂ°ä")
    try:
        json_str = match.group(1) if "```" in match.group(0) else match.group(0)
        return json.loads(json_str)
    except json.JSONDecodeError as e:
        print("‚ùå JSON decode error at character:", e.pos)
        print("‚õî ÂïèÈ°åÈôÑËøëÂÖßÂÆπÔºö", json_str[e.pos - 30:e.pos + 30])
        raise

async def classify_article(article: NewsEntity):
    user_prompt = f"""Ë´ãÂàÜÊûê‰ª•‰∏ãÊñ∞ËÅûÊñáÁ´†Ôºå‰∏¶‰æù system prompt ÁöÑÊ†ºÂºèËàáË¶èÂâáËº∏Âá∫ÁµêÊßãÂåñ JSON ÂàÜÊûêÁµêÊûú:

--- ARTICLE START ---
{article.content}
--- ARTICLE END ---
"""

    chat = model.start_chat(history=[
        {"role": "user", "parts": [system_prompt.strip()]},
        ])
    response = chat.send_message(user_prompt.strip())
    print("‚úÖ Gotten an LLM response")
    try:
        content = safe_parse_json(response.text)
        print("content:",content)
        print("‚úÖ Safely parsed the text")
    except Exception as e:
        print("‚ö†Ô∏è Failed to parse the json:", e)
        return None

    # Initialize safe defaults
    refined_title: Optional[str] = None
    reporting_style_out: List[str] = []
    reporting_intention_out: List[str] = []
    journalistic_demerits_out: Dict[str, AssessmentItem] = {}
    journalistic_merits_out: Dict[str, AssessmentItem] = {}

    def _normalize_degree(val: str) -> str:
        # Accept only your Degree literal, fallback to "low" if invalid
        allowed = {"low", "moderate", "high"}
        if isinstance(val, str) and val.lower() in allowed:
            return val.lower()
        # If model outputs "not applicable", just skip the item later (we only keep appeared tags)
        return "low"

    data = content
    if not isinstance(data, dict):
        print("‚ö†Ô∏è Parsed content is not a dict. Raw output:")
        print(content)
        return None
    # refined_title
    try:
        # refined_title
        path = "refined_title"
        expect(path in data, path, "Missing top-level key")
        rt = data.get(path)
        # allow null or string
        expect(rt is None or isinstance(rt, str), path, f"Expected null or string, got {type(rt).__name__}")
        refined_title = rt.strip() if isinstance(rt, str) and rt.strip() else None

        # reporting_style
        path = "reporting_style"
        expect(path in data, path, "Missing top-level key")
        rs = data.get(path)
        expect(isinstance(rs, list), path, f"Expected list, got {type(rs).__name__}")
        expect(all(isinstance(t, str) for t in rs), path, "All items must be strings")
        reporting_style_out = [t for t in rs if t in ALLOWED_TAGS["reporting_style"]]

        # reporting_intention
        path = "reporting_intention"
        expect(path in data, path, "Missing top-level key")
        ri = data.get(path)
        expect(isinstance(ri, list), path, f"Expected list, got {type(ri).__name__}")
        reporting_intention_out = [str(x).strip() for x in ri if isinstance(x, (str, int, float))][:3]

        # journalistic_demerits
        path = "journalistic_demerits"
        jd = data.get(path, {})
        expect(isinstance(jd, dict), path, f"Expected object, got {type(jd).__name__}")

        clean_allowed_demerits = set()
        for t in ALLOWED_TAGS["journalistic_demerits"]:
            clean = t.split("**")[1].strip() if t.startswith("**") and "**" in t[2:] else t
            clean = clean.replace("Ôºà", " ").replace("Ôºâ", " ").strip().split()[0]
            clean_allowed_demerits.add(clean)

        journalistic_demerits_out = {}
        for key, item in jd.items():
            key_path = f"{path}.{key}"
            expect(isinstance(item, dict), key_path, "Expected object for tag")
            clean_key = key.strip("* ").split("**")[-1] if "**" in key else key.strip()
            clean_key = clean_key.replace("Ôºà", " ").replace("Ôºâ", " ").strip().split()[0]
            if clean_key not in clean_allowed_demerits:
                # skip unknown tags silently or raise to be strict:
                # raise FieldError(f"Unknown demerit tag at '{key_path}': {clean_key}")
                continue
            desc = item.get("description", "")
            deg = (item.get("degree") or "").lower()
            expect(isinstance(desc, str), f"{key_path}.description", "Expected string")
            if desc.strip():
                if deg == "not applicable":
                    continue
                allowed_deg = {"low", "moderate", "high"}
                if deg and deg not in allowed_deg:
                    raise FieldError(f"Invalid degree '{deg}' at '{key_path}.degree' (allowed: {allowed_deg})")
                journalistic_demerits_out[clean_key] = {
                    "description": desc.strip(),
                    "degree": deg if deg in allowed_deg else "low",
                }

        # journalistic_merits
        path = "journalistic_merits"
        jm = data.get(path, {})
        expect(isinstance(jm, dict), path, f"Expected object, got {type(jm).__name__}")

        clean_allowed_merits = set()
        for t in ALLOWED_TAGS["journalistic_merits"]:
            clean = t.split("**")[1].strip() if t.startswith("**") and "**" in t[2:] else t
            clean = clean.replace("Ôºà", " ").replace("Ôºâ", " ").strip().split()[0]
            clean_allowed_merits.add(clean)

        journalistic_merits_out = {}
        for key, item in jm.items():
            key_path = f"{path}.{key}"
            expect(isinstance(item, dict), key_path, "Expected object for tag")
            clean_key = key.strip("* ").split("**")[-1] if "**" in key else key.strip()
            clean_key = clean_key.replace("Ôºà", " ").replace("Ôºâ", " ").strip().split()[0]
            if clean_key not in clean_allowed_merits:
                continue
            desc = item.get("description", "")
            deg = (item.get("degree") or "").lower()
            expect(isinstance(desc, str), f"{key_path}.description", "Expected string")
            if desc.strip():
                if deg == "not applicable":
                    continue
                allowed_deg = {"low", "moderate", "high"}
                if deg and deg not in allowed_deg:
                    raise FieldError(f"Invalid degree '{deg}' at '{key_path}.degree' (allowed: {allowed_deg})")
                journalistic_merits_out[clean_key] = {
                    "description": desc.strip(),
                    "degree": deg if deg in allowed_deg else "low",
                }

        # attach
        article.refined_title = refined_title
        article.reporting_style = reporting_style_out
        article.reporting_intention = reporting_intention_out
        article.journalistic_demerits = journalistic_demerits_out
        article.journalistic_merits = journalistic_merits_out
        return {
            "refined_title": refined_title,
            "reporting_style": reporting_style_out,
            "reporting_intention": reporting_intention_out,
            "journalistic_demerits": journalistic_demerits_out,
            "journalistic_merits": journalistic_merits_out
        }

    except Exception as e:
        # add article context to the error
        article_id = getattr(article, "id", None)
        article_url = getattr(article, "url", None)
        meta = f"(article_id={article_id}, url={article_url})"
        raise FieldError(f"{meta} {e}") from e

async def classify_articles(articles: List[NewsEntity]):
    tasks = [classify_article(article) for article in articles]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    return results